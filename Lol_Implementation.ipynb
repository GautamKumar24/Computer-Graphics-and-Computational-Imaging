{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers import add, Conv2D,MaxPooling2D,UpSampling2D, Input,BatchNormalization, RepeatVector, Reshape\n",
    "from keras.models import Model\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mounting Google Drive and loading the Lol_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive') \n",
    "\n",
    "InputPath=\"/content/drive/MyDrive/Graphics_dataset/high\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salt and Pepper noise function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def addNoise(image, noise_level=0.05):\n",
    "    # Copy the original image to avoid modifying it directly\n",
    "    noise_added_image = np.copy(image)\n",
    "\n",
    "    # Determine the number of noisy pixels\n",
    "    num_noisy_pixels = int(noise_level * image.size)\n",
    "\n",
    "    # Generate random indices for adding salt-and-pepper noise\n",
    "    indices = np.random.choice(np.arange(image.size), size=num_noisy_pixels, replace=False)\n",
    "\n",
    "    # Convert 1D indices to 2D coordinates\n",
    "    salt_coords = np.unravel_index(indices[:num_noisy_pixels // 2], image.shape)\n",
    "    pepper_coords = np.unravel_index(indices[num_noisy_pixels // 2:], image.shape)\n",
    "\n",
    "    # Add salt noise\n",
    "    noise_added_image[salt_coords] = 1\n",
    "\n",
    "    # Add pepper noise\n",
    "    noise_added_image[pepper_coords] = 0\n",
    "\n",
    "    return noise_added_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = cv.imread(InputPath + \"/100.png\")\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "\n",
    "# Add noise to the original image\n",
    "plt.subplot(1, 3, 2)\n",
    "Noise = addNoise(img)\n",
    "plt.imshow(Noise)\n",
    "plt.title('With Noise')\n",
    "\n",
    "# Convert the image to HSV and decrease the value channel\n",
    "plt.subplot(1, 3, 3)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "hsv[..., 2] = hsv[..., 2] * 0.2\n",
    "img1 = cv.cvtColor(hsv, cv.COLOR_HSV2RGB)\n",
    "\n",
    "# Add noise to the modified image\n",
    "Noise2 = addNoise(img1)\n",
    "plt.imshow(Noise2)\n",
    "plt.title('Modified with Noise')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "HighPath = \"/content/drive/MyDrive/Graphics_dataset/high\"\n",
    "\n",
    "def PreProcessData(ImagePath):\n",
    "    X_=[]\n",
    "    y_=[]\n",
    "    count=0\n",
    "    for imageName in tqdm(os.listdir(HighPath)):\n",
    "        count=count+1\n",
    "        low_img = cv.imread(HighPath + \"/\" + imageName)\n",
    "        low_img = cv.cvtColor(low_img, cv.COLOR_BGR2RGB)\n",
    "        low_img = cv.resize(low_img,(500,500))\n",
    "        hsv = cv.cvtColor(low_img, cv.COLOR_BGR2HSV) #convert it to hsv\n",
    "        hsv[...,2] = hsv[...,2]*0.2\n",
    "        img_1 = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "        Noisey_img = addNoise(img_1)\n",
    "        X_.append(Noisey_img)\n",
    "        y_.append(low_img)\n",
    "    X_ = np.array(X_)\n",
    "    y_ = np.array(y_)\n",
    "\n",
    "    return X_,y_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_,y_ = PreProcessData(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Implementation-Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def InstantiateModel(in_):\n",
    "\n",
    "    model_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(in_)\n",
    "    model_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_1)\n",
    "    model_1 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_1)\n",
    "\n",
    "    model_2 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(in_)\n",
    "    model_2 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n",
    "\n",
    "    model_2_0 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n",
    "\n",
    "    model_add = add([model_1,model_2,model_2_0])\n",
    "\n",
    "    model_3 = Conv2D(64,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "    model_3 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_3)\n",
    "    model_3 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3)\n",
    "\n",
    "    model_3_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "    model_3_1 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3_1)\n",
    "\n",
    "    model_3_2 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add)\n",
    "\n",
    "    model_add_2 = add([model_3_1,model_3_2,model_3])\n",
    "\n",
    "    model_4 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_2)\n",
    "    model_4_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "\n",
    "    model_add_3 = add([model_4_1,model_add_2,model_4])\n",
    "\n",
    "    model_5 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_3)\n",
    "    model_5 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add_3)\n",
    "\n",
    "    model_5 = Conv2D(3,(3,3), activation='relu',padding='same',strides=1)(model_5)\n",
    "\n",
    "    return model_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Sample = Input(shape=(500, 500,3))\n",
    "Output_ = InstantiateModel(Input_Sample)\n",
    "Model_Enhancer = Model(inputs=Input_Sample, outputs=Output_)\n",
    "Model_Enhancer.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "Model_Enhancer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "# Plot the Keras model and save it as an image\n",
    "plot_model(Model_Enhancer, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the image\n",
    "Image('model.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateInputs(X,y):\n",
    "    for i in range(len(X)):\n",
    "        X_input = X[i].reshape(1,500,500,3)\n",
    "        y_input = y[i].reshape(1,500,500,3)\n",
    "        yield (X_input,y_input)\n",
    "# Assuming Model_Enhancer is your Functional model\n",
    "Model_Enhancer.fit(GenerateInputs(X_, y_), epochs=53, verbose=1, steps_per_epoch=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPath =\"/content/drive/MyDrive/Graphics_dataset/high\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction and Evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractTestInput(ImagePath):\n",
    "    img = cv.imread(ImagePath)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img_ = cv.resize(img,(500,500))\n",
    "    hsv = cv.cvtColor(img_, cv.COLOR_BGR2HSV) #convert it to hsv\n",
    "    hsv[...,2] = hsv[...,2]*0.2\n",
    "    img1 = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    Noise = addNoise(img1)\n",
    "    Noise = Noise.reshape(1,500,500,3)\n",
    "    return Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePath=TestPath+\"/13.png\"\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.subplot(5,5,1)\n",
    "img_1 = cv.imread(ImagePath)\n",
    "img_1 = cv.cvtColor(img_1, cv.COLOR_BGR2RGB)\n",
    "img_1 = cv.resize(img_1, (500, 500))\n",
    "plt.title(\"Ground Truth\",fontsize=20)\n",
    "plt.imshow(img_1)\n",
    "\n",
    "plt.subplot(5,5,1+1)\n",
    "img_ = ExtractTestInput(ImagePath)\n",
    "img_ = img_.reshape(500,500,3)\n",
    "plt.title(\"Low Light Image\",fontsize=20)\n",
    "plt.imshow(img_)\n",
    "\n",
    "plt.subplot(5,5,1+2)\n",
    "image_for_test = ExtractTestInput(ImagePath)\n",
    "Prediction = Model_Enhancer.predict(image_for_test)\n",
    "Prediction = Prediction.reshape(500,500,3)\n",
    "img_[:,:,:] = Prediction[:,:,:]\n",
    "plt.title(\"Enhanced Image\",fontsize=20)\n",
    "plt.imshow(img_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
